---
title: "IS605_HW5"
author: "Daina Bouquin"
date: "Friday, March 4, 2016"
output: html_document
---
___  
#### Problem Set 1
Consider the unsolvable system $Ax = b$:
$$
\begin{bmatrix} 1 & 0 \\ 1 & 1 \\ 1 & 3 \\ 1 & 4 \end{bmatrix}
\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} =
\begin{bmatrix} 0 \\ 8 \\ 8 \\ 20 \end{bmatrix}
$$
   
1. Write R markdown script to compute $A^T A$ and $A^T b$
```{r}
# Create matrix A and the constraint vector b matrix
A <- matrix(c(1,0,1,1,1,3,1,4), byrow=TRUE, nrow=4)
b <- matrix(c(0,8,8,20), nrow=4)
# t() == transpose
ATA <- t(A) %*% A
ATb <- t(A) %*% b
```
   
2. Solve for $\hat{x}$ in R using the above two computed matrices.
```{r}
x_hat <- solve(ATA) %*% ATb
x_hat
# check work with lsfit() -- the least squares estimate of b
x_hat_check <- lsfit(A,b,intercept=FALSE)
# logical test
round(x_hat) == round(x_hat_check$coefficients)
```
   
3. What is the squared error of this solution?   
$p=A \hat{x}$   
$\hat{x}$ has been found, but we need to find p.   
$b = p + e$ therefore the error vector $e = b - p$.
```{r}
p <- A %*% x_hat
# compute the error vector e = b - p
e <- b-p
# Compare the error vector, with lsfit() like before - residuals
round(e) == round(x_hat_check$residuals)
# Find the squared error
sq_e <- sum(e^2)
sq_e
```
   
4. Instead of $b = [0; 8; 8; 20]$, start with $p = [1; 5; 13; 17]$ and find the exact solution (i.e. show that this system is solvable as all equations are consistent with each other. This should result in an error vector e = 0).
```{r}
# find the A^T p. Already have (A^T A)A-1.
p = matrix(c(1,5,13,17), nrow=4) # from prompt
ATp <- t(A) %*% p
```
Find $\hat{x}$ by finding $(A^T A)^{-1} (A^T p)$
```{r}
x_hat_p <- solve(ATA) %*% ATp
# p=Ax
p2 <- A %*% x_hat_p
p2
# calculate error
e2 <- round(p2-p)
sq_e2 <- round(sum(e2^2), digits=6)
sq_e2 # equals zero
```
    
5. Show that the error $e = b - p = [-1; 3;-5; 3]$
```{r}
res_error <- b-p
res_error
```
   
6. Show that the error $e$ is orthogonal to $p$ and to each of the columns of A.
```{r}
# orthogonal vectors' dot product == zero. 
# e and p are orthogonal
round(sum(e*p))

#e and the columns of A are orthogonal
round(sum(e*A[,1]))
round(sum(e*A[,2]))
```
___   
#### Problem Set 2
Consider the modified auto-mpg data (obtained from the UC Irvine Machine Learning dataset). This dataset contains 5 columns: $displacement, horsepower, weight, acceleration, mpg$. We are going to model $mpg$ as a function of the other four variables.
```{r}
auto_data <- read.table('auto-mpg.data', 
                        col.names=c('disp', 'hp', 'wt', 'acc', 'mpg'))
# check that the files read in properly
# categorical variables found in original dataset have been removed
str(auto_data)
```
1. Write an R markdown script that takes in the auto-mpg data, extracts an A matrix from the first 4 columns and b vector from the fifth (mpg) column. 
```{r}
# convert the dataframe into matrices
A <- data.matrix(auto_data[,1:4])
A <- cbind(rep(1,nrow(A)),A)  # column of repeating 1 for the intercepts
b <- data.matrix(auto_data[,5])
head(A)
head(b)
```
2. Using the least squares approach, your code should compute the best fitting solution. That is, find the best fitting equation that expresses mpg in terms of the other 4 variables.   
```{r}
# x_hat approximates the solution of Ax=b
ATA <- t(A) %*% A
ATb <- t(A) %*% b
# calculate x_hat for best fitting solution
x_hat <- solve(ATA) %*% ATb
x_hat
```
3. Calculate the fitting error between the predicted mpg of your model and the actual mpg.
```{r}
p <- A %*% x_hat
e <- b-p
sq_e <- sum(e^2)
sq_e
# check it with lsfit()
ls_check <- lsfit(A, b, intercept=FALSE) 
# logical test
round(x_hat) == round(ls_check$coefficients)
```